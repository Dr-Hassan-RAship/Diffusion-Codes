{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 64, 32, 32])\n",
      "Output shape: torch.Size([2, 64, 32, 32])\n",
      "Attention weights shape: torch.Size([2, 64])\n",
      "Sample attention weights for first sample:\n",
      "tensor([0.4997, 0.5000, 0.5000, 0.5002, 0.4997])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define SELayer (as provided)\n",
    "class SELayer(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SELayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "# Create a sample input tensor\n",
    "batch_size, channels, height, width = 2, 64, 32, 32\n",
    "x = torch.randn(batch_size, channels, height, width)  # Simulated feature map\n",
    "\n",
    "# Instantiate SELayer\n",
    "se_layer = SELayer(channel=channels, reduction=16)\n",
    "\n",
    "# Forward pass\n",
    "output = se_layer(x)\n",
    "\n",
    "# Print shapes and sample attention weights\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "\n",
    "# Extract attention weights for inspection\n",
    "with torch.no_grad():\n",
    "    y = se_layer.avg_pool(x).view(batch_size, channels)\n",
    "    y = se_layer.fc(y)\n",
    "    print(f\"Attention weights shape: {y.shape}\")\n",
    "    print(f\"Sample attention weights for first sample:\\n{y[0][:5]}\")  # First 5 channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 64, 32, 32])\n",
      "Output shape: torch.Size([2, 64, 32, 32])\n",
      "Attention map shape: torch.Size([2, 1024, 256])\n",
      "Sample attention weights (first 5x5 for first sample):\n",
      "tensor([[0.0052, 0.0056, 0.0017, 0.0021, 0.0009],\n",
      "        [0.0016, 0.0070, 0.0040, 0.0005, 0.0004],\n",
      "        [0.0097, 0.0216, 0.0051, 0.0020, 0.0051],\n",
      "        [0.0087, 0.0036, 0.0016, 0.0019, 0.0107],\n",
      "        [0.0001, 0.0020, 0.0030, 0.0100, 0.0002]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define NonLocalBlock (as provided)\n",
    "class NonLocalBlock(nn.Module):\n",
    "    def __init__(self, in_channels, inter_channels=None, sub_sample=True, bn_layer=True):\n",
    "        super(NonLocalBlock, self).__init__()\n",
    "        self.sub_sample = sub_sample\n",
    "        self.in_channels = in_channels\n",
    "        self.inter_channels = inter_channels\n",
    "        if self.inter_channels is None:\n",
    "            self.inter_channels = in_channels // 2\n",
    "            if self.inter_channels == 0:\n",
    "                self.inter_channels = 1\n",
    "        self.g = nn.Conv2d(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                           kernel_size=1, stride=1, padding=0)\n",
    "        if bn_layer:\n",
    "            self.W = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=self.inter_channels, out_channels=self.in_channels,\n",
    "                          kernel_size=1, stride=1, padding=0),\n",
    "                nn.BatchNorm2d(self.in_channels)\n",
    "            )\n",
    "            nn.init.constant_(self.W[1].weight, 0)\n",
    "            nn.init.constant_(self.W[1].bias, 0)\n",
    "        else:\n",
    "            self.W = nn.Conv2d(in_channels=self.inter_channels, out_channels=self.in_channels,\n",
    "                               kernel_size=1, stride=1, padding=0)\n",
    "            nn.init.constant_(self.W.weight, 0)\n",
    "            nn.init.constant_(self.W.bias, 0)\n",
    "        self.theta = nn.Conv2d(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                               kernel_size=1, stride=1, padding=0)\n",
    "        self.phi = nn.Conv2d(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                             kernel_size=1, stride=1, padding=0)\n",
    "        if sub_sample:\n",
    "            self.g = nn.Sequential(self.g, nn.MaxPool2d(kernel_size=(2, 2)))\n",
    "            self.phi = nn.Sequential(self.phi, nn.MaxPool2d(kernel_size=(2, 2)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        g_x = self.g(x).view(batch_size, self.inter_channels, -1)\n",
    "        g_x = g_x.permute(0, 2, 1)\n",
    "        theta_x = self.theta(x).view(batch_size, self.inter_channels, -1)\n",
    "        theta_x = theta_x.permute(0, 2, 1)\n",
    "        phi_x = self.phi(x).view(batch_size, self.inter_channels, -1)\n",
    "        f = torch.matmul(theta_x, phi_x)\n",
    "        f_div_C = F.softmax(f, dim=-1)\n",
    "        y = torch.matmul(f_div_C, g_x)\n",
    "        y = y.permute(0, 2, 1).contiguous()\n",
    "        y = y.view(batch_size, self.inter_channels, *x.size()[2:])\n",
    "        W_y = self.W(y)\n",
    "        z = W_y + x\n",
    "        return z\n",
    "\n",
    "# Create a sample input tensor\n",
    "batch_size, in_channels, height, width = 2, 64, 32, 32\n",
    "x = torch.randn(batch_size, in_channels, height, width)  # Simulated feature map\n",
    "\n",
    "# Instantiate NonLocalBlock\n",
    "non_local_block = NonLocalBlock(in_channels=in_channels, inter_channels=None, sub_sample=True, bn_layer=True)\n",
    "\n",
    "# Forward pass\n",
    "output = non_local_block(x)\n",
    "\n",
    "# Print shapes and sample attention weights\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "\n",
    "# Extract attention map for inspection\n",
    "with torch.no_grad():\n",
    "    g_x = non_local_block.g(x).view(batch_size, non_local_block.inter_channels, -1)\n",
    "    theta_x = non_local_block.theta(x).view(batch_size, non_local_block.inter_channels, -1).permute(0, 2, 1)\n",
    "    phi_x = non_local_block.phi(x).view(batch_size, non_local_block.inter_channels, -1)\n",
    "    f = torch.matmul(theta_x, phi_x)\n",
    "    f_div_C = F.softmax(f, dim=-1)\n",
    "    print(f\"Attention map shape: {f_div_C.shape}\")\n",
    "    print(f\"Sample attention weights (first 5x5 for first sample):\\n{f_div_C[0, :5, :5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1.shape: torch.Size([2, 3, 352, 352]), x2.shape: torch.Size([2, 3, 176, 176]), x3.shape: torch.Size([2, 3, 88, 88])\n",
      "x2.shape: torch.Size([2, 3, 352, 352])\n",
      "x3.shape: torch.Size([2, 3, 352, 352])\n",
      "feat.shape: torch.Size([2, 9, 352, 352])\n",
      "y1.shape: torch.Size([2, 9, 1, 1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, expected weight to be at least 1 at dimension 0, but got weight of size [0, 3, 1, 1] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 62\u001b[39m\n\u001b[32m     59\u001b[39m hppf = HPPF(in_channels=in_channels)\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m output = \u001b[43mhppf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx3\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# Extract attention weights for inspection\u001b[39;00m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/TaN2/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/TaN2/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36mHPPF.forward\u001b[39m\u001b[34m(self, x1, x2, x3)\u001b[39m\n\u001b[32m     32\u001b[39m y1 = \u001b[38;5;28mself\u001b[39m.avg(feat)\n\u001b[32m     33\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33my1.shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my1.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m y2 = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeat\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (2, 192, 4, 4)\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33my2.shape before reshape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my2.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     36\u001b[39m y3 = \u001b[38;5;28mself\u001b[39m.conv2(\u001b[38;5;28mself\u001b[39m.max2(feat))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/TaN2/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/TaN2/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/TaN2/lib/python3.11/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/TaN2/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/TaN2/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/TaN2/lib/python3.11/site-packages/torch/nn/modules/conv.py:554\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/TaN2/lib/python3.11/site-packages/torch/nn/modules/conv.py:549\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    539\u001b[39m         F.pad(\n\u001b[32m    540\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    547\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    548\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Given groups=1, expected weight to be at least 1 at dimension 0, but got weight of size [0, 3, 1, 1] instead"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define HPPF (as provided)\n",
    "class HPPF(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(HPPF, self).__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(in_channels, in_channels // 16, 1, 1), nn.ReLU(inplace=True))\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(in_channels, in_channels // 64, 1, 1), nn.ReLU(inplace=True))\n",
    "        self.avg   = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max1  = nn.AdaptiveMaxPool2d(4)\n",
    "        self.max2  = nn.AdaptiveMaxPool2d(8)\n",
    "        self.mlp   = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels // 8, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels // 8, in_channels, kernel_size=1),\n",
    "            nn.Sigmoid())\n",
    "        self.feat_conv = nn.Sequential(nn.Conv2d(in_channels, in_channels // 3, 3, 1, 1),\n",
    "                                       nn.BatchNorm2d(in_channels // 3),\n",
    "                                       nn.ReLU(inplace=True))\n",
    "\n",
    "    def forward(self, x1, x2, x3):\n",
    "        print(f'x1.shape: {x1.shape}, x2.shape: {x2.shape}, x3.shape: {x3.shape}')\n",
    "        x2 = F.interpolate(x2, size=x1.size()[2:], mode='bilinear', align_corners=True)\n",
    "        print(f'x2.shape: {x2.shape}')\n",
    "        x3 = F.interpolate(x3, size=x1.size()[2:], mode='bilinear', align_corners=True)\n",
    "        print(f'x3.shape: {x3.shape}')\n",
    "        feat = torch.cat((x1, x2, x3), 1)\n",
    "        print(f'feat.shape: {feat.shape}')\n",
    "        b, c, h, w = feat.size()\n",
    "        y1 = self.avg(feat)\n",
    "        print(f\"y1.shape: {y1.shape}\")\n",
    "        y2 = self.conv1(self.max1(feat)) # (2, 192, 4, 4)\n",
    "        print(f\"y2.shape before reshape: {y2.shape}\")\n",
    "        y3 = self.conv2(self.max2(feat))\n",
    "        print(f\"y3.shape before reshape: {y3.shape}\")\n",
    "        y2 = y2.reshape(b, c, 1, 1)\n",
    "        print(f\"y2.shape after reshape: {y2.shape}\")\n",
    "        y3 = y3.reshape(b, c, 1, 1)\n",
    "        print(f\"y3.shape after reshape: {y3.shape}\")\n",
    "        z = (y1 + y2 + y3) // 3\n",
    "        print(f'z.shape: {z.shape}')\n",
    "        attention = self.mlp(z)\n",
    "        print(f\"attention.shape: {attention.shape}\")\n",
    "        output1 = attention * feat\n",
    "        print(f\"output1.shape: {output1.shape}\")\n",
    "        output2 = self.feat_conv(output1)\n",
    "        print(f'output2.shape: {output2.shape}')\n",
    "        return output2\n",
    "\n",
    "# Create sample input tensors\n",
    "batch_size, in_channels, height, width = 2, 3, 352, 352\n",
    "x1 = torch.randn(batch_size, in_channels, height, width)  # Feature map at highest resolution\n",
    "x2 = torch.randn(batch_size, in_channels, height//2, width//2)  # Lower resolution\n",
    "x3 = torch.randn(batch_size, in_channels, height//4, width//4)  # Lowest resolution\n",
    "\n",
    "# Instantiate HPPF\n",
    "hppf = HPPF(in_channels=in_channels)\n",
    "\n",
    "# Forward pass\n",
    "output = hppf(x1, x2, x3)\n",
    "\n",
    "# Extract attention weights for inspection\n",
    "with torch.no_grad():\n",
    "    x2_up = F.interpolate(x2, size=x1.size()[2:], mode='bilinear', align_corners=True)\n",
    "    x3_up = F.interpolate(x3, size=x1.size()[2:], mode='bilinear', align_corners=True)\n",
    "    feat = torch.cat((x1, x2_up, x3_up), 1)\n",
    "    y1 = hppf.avg(feat)\n",
    "    y2 = hppf.conv1(hppf.max1(feat)).reshape(batch_size, 3 * in_channels, 1, 1)\n",
    "    y3 = hppf.conv2(hppf.max2(feat)).reshape(batch_size, 3 * in_channels, 1, 1)\n",
    "    z = (y1 + y2 + y3) // 3\n",
    "    attention = hppf.mlp(z)\n",
    "    print(f\"Attention weights shape: {attention.shape}\")\n",
    "    print(f\"Sample attention weights (first 5 channels):\\n{attention[0, :5, 0, 0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TaN2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
