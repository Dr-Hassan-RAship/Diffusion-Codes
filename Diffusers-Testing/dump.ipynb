{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ee/anaconda3/envs/TaN2/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.draw import disk, polygon\n",
    "from glob import glob\n",
    "import cv2\n",
    "\n",
    "import                              torch, copy\n",
    "import                              torch.nn as nn\n",
    "\n",
    "from config                         import *\n",
    "from diffusers                      import (AutoencoderKL, DDPMScheduler, UNet2DModel, DDIMScheduler)\n",
    "# from source_unet_2d                 import UNet2DModel\n",
    "from modeling_utils                 import *\n",
    "from peft                           import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "# root_dir = 'C:/Users/Talha/OneDrive - Higher Education Commission/Documents/GitHub/Diffusion-Codes/Diffusers-Testing'\n",
    "# os.chdir(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics saved to C:/Users/Talha/OneDrive - Higher Education Commission/Documents/GitHub/Diffusion-Codes/Diffusers-Testing/testing_analysis\\uncertainty_metrics.csv\n",
      "âœ… Uncertainty metrics saved to C:/Users/Talha/OneDrive - Higher Education Commission/Documents/GitHub/Diffusion-Codes/Diffusers-Testing/testing_analysis\\uncertainty_metrics.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-23 19:32:07.875131: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-23 19:32:09.852653: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "!python uncertainty_analysis.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>GT_Components</th>\n",
       "      <th>Pred_Components</th>\n",
       "      <th>Component_Diff</th>\n",
       "      <th>GT_Smoothness</th>\n",
       "      <th>Pred_Smoothness</th>\n",
       "      <th>Smoothness_Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>([1.0765577989436452], 1.0765577989436452)</td>\n",
       "      <td>([1.0765577989436452], 1.0765577989436452)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>([1.0700973119248192, 1.0570850420432631], 1.0...</td>\n",
       "      <td>([1.0700973119248192, nan], nan)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>([1.3657568924106536], 1.3657568924106536)</td>\n",
       "      <td>([1.3657568924106536], 1.3657568924106536)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>([1.3657568924106536, 1.075845765087769], 1.22...</td>\n",
       "      <td>([1.075845765087769, nan], nan)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient_ID  GT_Components  Pred_Components  Component_Diff  \\\n",
       "0           0              1                1               0   \n",
       "1           1              2                1               1   \n",
       "2           2              1                1               0   \n",
       "3           3              2                1               1   \n",
       "\n",
       "                                       GT_Smoothness  \\\n",
       "0         ([1.0765577989436452], 1.0765577989436452)   \n",
       "1  ([1.0700973119248192, 1.0570850420432631], 1.0...   \n",
       "2         ([1.3657568924106536], 1.3657568924106536)   \n",
       "3  ([1.3657568924106536, 1.075845765087769], 1.22...   \n",
       "\n",
       "                              Pred_Smoothness  Smoothness_Diff  \n",
       "0  ([1.0765577989436452], 1.0765577989436452)              0.0  \n",
       "1            ([1.0700973119248192, nan], nan)              NaN  \n",
       "2  ([1.3657568924106536], 1.3657568924106536)              0.0  \n",
       "3             ([1.075845765087769, nan], nan)              NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path = 'testing_analysis/uncertainty_metrics.csv'\n",
    "\n",
    "pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size  = 2\n",
    "device      = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "noise_pred  = torch.randn(batch_size, 4, 32, 32).to(device)\n",
    "scheduler   = DDPMScheduler(num_train_timesteps=1000, beta_start = BETA_START, beta_end = BETA_END, beta_schedule = NOISE_SCHEDULER)\n",
    "t           = torch.randint(0, scheduler.config.num_train_timesteps, (noise_pred.size(0),), device=device).long()\n",
    "zt          = torch.randn(batch_size, 4, 32, 32).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise_and_decode_in_one_step(batch_size, noise_pred, timesteps, zt, scheduler, device, inference = False):\n",
    "    \n",
    "    \"\"\"\n",
    "    Denoise and decode the latent zt to obtain the predicted mask.\n",
    "    \"\"\"\n",
    "    z0_hat_list   = []\n",
    "        \n",
    "    if inference:\n",
    "        noise_pred = noise_pred.to(device = 'cpu') \n",
    "        timesteps  = timesteps.to(device = 'cpu') \n",
    "        zt         = zt.to(device = 'cpu')\n",
    "        \n",
    "    for batch_idx in range(noise_pred.shape[0]):\n",
    "        # z0_hat = (zt - ((1 - scheduler.alphas_cumprod).sqrt() * noise_pred)) / scheduler.alphas_cumprod.sqrt()\n",
    "        # z0_hat   = scheduler.step(noise_pred[batch_idx].unsqueeze(0), timesteps[batch_idx].unsqueeze(0), zt[batch_idx].unsqueeze(0)).pred_original_sample\n",
    "        alpha_t                     = scheduler.alphas_cumprod[timesteps[batch_idx].item()]\n",
    "        z0_hat                      = (zt[batch_idx].unsqueeze(0) - (1 - alpha_t).sqrt() * noise_pred[batch_idx].unsqueeze(0)) / alpha_t.sqrt()\n",
    "        z0_hat_list.append(z0_hat)\n",
    "    \n",
    "    z0_hat   = torch.cat(z0_hat_list,   dim = 0) # (B, 4, 32, 32)\n",
    "    \n",
    "    return z0_hat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "z0_hat = denoise_and_decode_in_one_step(batch_size, noise_pred, t, zt, scheduler, device, inference = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "z0_hat1 = denoise_and_decode_in_one_step(batch_size, noise_pred, t, zt, scheduler, device, inference = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 32, 32])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z0_hat1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(z0_hat.to(device), z0_hat1.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
