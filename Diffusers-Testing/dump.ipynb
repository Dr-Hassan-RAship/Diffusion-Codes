{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ee/anaconda3/envs/TaN2/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.draw import disk, polygon\n",
    "from glob import glob\n",
    "import cv2\n",
    "\n",
    "import                              torch, copy\n",
    "import                              torch.nn as nn\n",
    "\n",
    "from config                         import *\n",
    "from diffusers                      import (AutoencoderKL, DDPMScheduler, UNet2DModel, DDIMScheduler)\n",
    "# from source_unet_2d                 import UNet2DModel\n",
    "from modeling_utils                 import *\n",
    "from peft                           import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "# root_dir = 'C:/Users/Talha/OneDrive - Higher Education Commission/Documents/GitHub/Diffusion-Codes/Diffusers-Testing'\n",
    "# os.chdir(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics saved to C:/Users/Talha/OneDrive - Higher Education Commission/Documents/GitHub/Diffusion-Codes/Diffusers-Testing/testing_analysis\\uncertainty_metrics.csv\n",
      "âœ… Uncertainty metrics saved to C:/Users/Talha/OneDrive - Higher Education Commission/Documents/GitHub/Diffusion-Codes/Diffusers-Testing/testing_analysis\\uncertainty_metrics.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-23 19:32:07.875131: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-23 19:32:09.852653: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "!python uncertainty_analysis.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>GT_Components</th>\n",
       "      <th>Pred_Components</th>\n",
       "      <th>Component_Diff</th>\n",
       "      <th>GT_Smoothness</th>\n",
       "      <th>Pred_Smoothness</th>\n",
       "      <th>Smoothness_Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>([1.0765577989436452], 1.0765577989436452)</td>\n",
       "      <td>([1.0765577989436452], 1.0765577989436452)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>([1.0700973119248192, 1.0570850420432631], 1.0...</td>\n",
       "      <td>([1.0700973119248192, nan], nan)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>([1.3657568924106536], 1.3657568924106536)</td>\n",
       "      <td>([1.3657568924106536], 1.3657568924106536)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>([1.3657568924106536, 1.075845765087769], 1.22...</td>\n",
       "      <td>([1.075845765087769, nan], nan)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient_ID  GT_Components  Pred_Components  Component_Diff  \\\n",
       "0           0              1                1               0   \n",
       "1           1              2                1               1   \n",
       "2           2              1                1               0   \n",
       "3           3              2                1               1   \n",
       "\n",
       "                                       GT_Smoothness  \\\n",
       "0         ([1.0765577989436452], 1.0765577989436452)   \n",
       "1  ([1.0700973119248192, 1.0570850420432631], 1.0...   \n",
       "2         ([1.3657568924106536], 1.3657568924106536)   \n",
       "3  ([1.3657568924106536, 1.075845765087769], 1.22...   \n",
       "\n",
       "                              Pred_Smoothness  Smoothness_Diff  \n",
       "0  ([1.0765577989436452], 1.0765577989436452)              0.0  \n",
       "1            ([1.0700973119248192, nan], nan)              NaN  \n",
       "2  ([1.3657568924106536], 1.3657568924106536)              0.0  \n",
       "3             ([1.075845765087769, nan], nan)              NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path = 'testing_analysis/uncertainty_metrics.csv'\n",
    "\n",
    "pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size  = 2\n",
    "device      = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "noise_pred  = torch.randn(batch_size, 4, 32, 32).to(device)\n",
    "scheduler   = DDPMScheduler(num_train_timesteps=1000, beta_start = BETA_START, beta_end = BETA_END, beta_schedule = NOISE_SCHEDULER)\n",
    "t           = torch.randint(0, scheduler.config.num_train_timesteps, (noise_pred.size(0),), device=device).long()\n",
    "zt          = torch.randn(batch_size, 4, 32, 32).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise_and_decode_in_one_step(batch_size, noise_pred, timesteps, zt, scheduler, device, inference = False):\n",
    "    \n",
    "    \"\"\"\n",
    "    Denoise and decode the latent zt to obtain the predicted mask.\n",
    "    \"\"\"\n",
    "    z0_hat_list   = []\n",
    "        \n",
    "    if inference:\n",
    "        noise_pred = noise_pred.to(device = 'cpu') \n",
    "        timesteps  = timesteps.to(device = 'cpu') \n",
    "        zt         = zt.to(device = 'cpu')\n",
    "        \n",
    "    for batch_idx in range(noise_pred.shape[0]):\n",
    "        # z0_hat = (zt - ((1 - scheduler.alphas_cumprod).sqrt() * noise_pred)) / scheduler.alphas_cumprod.sqrt()\n",
    "        # z0_hat   = scheduler.step(noise_pred[batch_idx].unsqueeze(0), timesteps[batch_idx].unsqueeze(0), zt[batch_idx].unsqueeze(0)).pred_original_sample\n",
    "        alpha_t                     = scheduler.alphas_cumprod[timesteps[batch_idx].item()]\n",
    "        z0_hat                      = (zt[batch_idx].unsqueeze(0) - (1 - alpha_t).sqrt() * noise_pred[batch_idx].unsqueeze(0)) / alpha_t.sqrt()\n",
    "        z0_hat_list.append(z0_hat)\n",
    "    \n",
    "    z0_hat   = torch.cat(z0_hat_list,   dim = 0) # (B, 4, 32, 32)\n",
    "    \n",
    "    return z0_hat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "z0_hat = denoise_and_decode_in_one_step(batch_size, noise_pred, t, zt, scheduler, device, inference = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "z0_hat1 = denoise_and_decode_in_one_step(batch_size, noise_pred, t, zt, scheduler, device, inference = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 32, 32])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z0_hat1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(z0_hat.to(device), z0_hat1.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    \"\"\"Dice Loss PyTorch\n",
    "        Created by: Zhang Shuai\n",
    "        Email: shuaizzz666@gmail.com\n",
    "        dice_loss = 1 - 2*p*t / (p^2 + t^2). p and t represent predict and target.\n",
    "    Args:\n",
    "        weight: An array of shape [C,]\n",
    "        predict: A float32 tensor of shape [N, C, *], for Semantic segmentation task is [N, C, H, W]\n",
    "        target: A int64 tensor of shape [N, *], for Semantic segmentation task is [N, H, W]\n",
    "    Return:\n",
    "        diceloss\n",
    "    \"\"\"\n",
    "    def __init__(self, weight=None):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        if weight is not None:\n",
    "            weight = torch.Tensor(weight)\n",
    "            self.weight = weight / torch.sum(weight) # Normalized weight\n",
    "        self.smooth = 1e-5\n",
    "\n",
    "    def forward(self, predict, target):\n",
    "        N, C = predict.size()[:2]\n",
    "        predict = predict.view(N, C, -1) # (N, C, *)\n",
    "        target = target.view(N, 1, -1) # (N, 1, *)\n",
    "\n",
    "        predict = F.softmax(predict, dim=1) # (N, C, *) ==> (N, C, *)\n",
    "        ## convert target(N, 1, *) into one hot vector (N, C, *)\n",
    "        target_onehot = torch.zeros(predict.size()).cuda()  # (N, 1, *) ==> (N, C, *)\n",
    "        target_onehot.scatter_(1, target, 1)  # (N, C, *)\n",
    "\n",
    "        intersection = torch.sum(predict * target_onehot, dim=2)  # (N, C)\n",
    "        union = torch.sum(predict.pow(2), dim=2) + torch.sum(target_onehot, dim=2)  # (N, C)\n",
    "        ## p^2 + t^2 >= 2*p*t, target_onehot^2 == target_onehot\n",
    "        dice_coef = (2 * intersection + self.smooth) / (union + self.smooth)  # (N, C)\n",
    "\n",
    "        if hasattr(self, 'weight'):\n",
    "            if self.weight.type() != predict.type():\n",
    "                self.weight = self.weight.type_as(predict)\n",
    "                dice_coef = dice_coef * self.weight * C  # (N, C)\n",
    "        dice_loss = 1 - torch.mean(dice_coef)  # 1\n",
    "\n",
    "        return dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_target  = torch.Tensor([[0, 1], [1, 0]]).long().cuda(0)\n",
    "y_predict = torch.randn(2, 2, 256, 256).cuda(0)  # Simulated predictions for two classes\n",
    "\n",
    "criterion = DiceLoss(weight=[1, 1])\n",
    "loss = criterion(y_predict, y_target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 2]), torch.Size([2, 2, 256, 256]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_target.shape, y_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TaN2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
